{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5f2ef7",
   "metadata": {},
   "source": [
    "# Object Detection without GUI\n",
    "\n",
    "This project is an object detection system that can detect objects in a video stream or webcam feed and record the video with highlighted objects. It utilizes the OpenCV library and a pre-trained deep learning model for object detection.\n",
    "\n",
    "To use this code:\n",
    "\n",
    "1. **Process the Video File:** Use the process_video() method to detect objects in a selected video file. After selecting the video file and configuring the necessary parameters, call object_detector.process_video() to start the object detection process. The processed video will be displayed with bounding boxes around the detected objects, and the frames per second (FPS) will be shown in the top left corner.\n",
    "\n",
    "2. **Process the Webcam Feed:** Use the process_webcam() method to detect objects in the webcam feed. Call object_detector.process_webcam() to initiate the object detection process. The webcam feed will be displayed with bounding boxes around the detected objects. To stop the webcam feed, press the 'q' key or close the window.\n",
    "\n",
    "Please note that the object detection model used in this project is trained on the COCO dataset, which encompasses a wide variety of objects. Detected objects will be labeled with their class names and confidence scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4e9f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "15b3f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c143b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector:\n",
    "    def __init__(self, video_path, config_path, model_path, classes_path, output_path):\n",
    "        \"\"\"\n",
    "        Initializes the ObjectDetector class with the given parameters.\n",
    "\n",
    "        Args:\n",
    "        - video_path: The path to the input video file or the webcam index (int) for live video.\n",
    "        - config_path: The path to the model configuration file.\n",
    "        - model_path: The path to the model weights file.\n",
    "        - classes_path: The path to the file containing class labels.\n",
    "        - output_path: The path to save the output video.\n",
    "        \"\"\"\n",
    "        self.video_path = video_path\n",
    "        self.config_path = config_path\n",
    "        self.model_path = model_path\n",
    "        self.classes_path = classes_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "        # Initialize the object detection model\n",
    "        self.net = cv2.dnn_DetectionModel(self.model_path, self.config_path)\n",
    "        self.net.setInputSize(320, 320)\n",
    "        self.net.setInputScale(1.0/127.5)\n",
    "        self.net.setInputMean((127.5, 127.5, 127.5))\n",
    "        self.net.setInputSwapRB(True)\n",
    "\n",
    "        # Read the class labels and assign random colors to each class\n",
    "        self.read_classes()\n",
    "\n",
    "    def read_classes(self):\n",
    "        \"\"\"\n",
    "        Reads the class labels from the file and assigns random -colors to each class.\n",
    "        \"\"\"\n",
    "        with open(self.classes_path, 'r') as f:\n",
    "            self.classes_list = f.read().splitlines()\n",
    "\n",
    "        self.classes_list.insert(0, '__Background__')\n",
    "\n",
    "        self.color_list = np.random.uniform(low=0, high=255, size=(len(self.classes_list), 3))\n",
    "\n",
    "    def detect_objects(self, image):\n",
    "        \"\"\"\n",
    "        Detects objects in the given image and draws bounding boxes around them.\n",
    "\n",
    "        Args:\n",
    "        - image: The input image to detect objects in.\n",
    "        \"\"\"\n",
    "        class_label_ids, confidences, bboxes = self.net.detect(image, confThreshold=0.4)\n",
    "\n",
    "        bboxes = list(bboxes)\n",
    "        confidences = list(np.array(confidences).reshape(1, -1)[0])\n",
    "        confidences = list(map(float, confidences))\n",
    "\n",
    "        bbox_indices = cv2.dnn.NMSBoxes(bboxes, confidences, score_threshold=0.5, nms_threshold=0.2)\n",
    "\n",
    "        if len(bbox_indices) != 0:\n",
    "            for i in range(len(bbox_indices)):\n",
    "                bbox = bboxes[np.squeeze(bbox_indices[i])]\n",
    "                class_confidence = confidences[np.squeeze(bbox_indices[i])]\n",
    "                class_label_id = np.squeeze(class_label_ids[np.squeeze(bbox_indices[i])])\n",
    "                class_label = self.classes_list[class_label_id].upper()\n",
    "                class_color = [int(c) for c in self.color_list[class_label_id]]\n",
    "\n",
    "                display_text = \"{}: {:.2f}\".format(class_label, class_confidence)\n",
    "\n",
    "                x, y, w, h = bbox\n",
    "\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), color=class_color, thickness=1)\n",
    "                cv2.putText(image, display_text, (x, y - 10), cv2.FONT_HERSHEY_PLAIN, 1, class_color, 2)\n",
    "\n",
    "    def process_video(self):\n",
    "        \"\"\"\n",
    "        Processes the input video file and saves the output with the detected objects.\n",
    "        \"\"\"\n",
    "        if self.video_path.isnumeric():\n",
    "            cap = cv2.VideoCapture(int(self.video_path))\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error opening video file...\")\n",
    "            return\n",
    "\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(self.output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        start_time = 0\n",
    "\n",
    "        while True:\n",
    "            success, image = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            current_time = time.time()\n",
    "            fps = 1 / (current_time - start_time)\n",
    "            start_time = current_time\n",
    "\n",
    "            self.detect_objects(image)\n",
    "\n",
    "            cv2.putText(image, \"FPS: \" + str(int(fps)), (20, 70), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Result\", image)\n",
    "\n",
    "            out.write(image)  # Write the frame to the video writer\n",
    "\n",
    "            # Wait for key press and check if 'q' is pressed\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        # Release video capture, video writer, and destroy windows\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def process_webcam(self):\n",
    "        \"\"\"\n",
    "        Processes the live video from the webcam and saves the output with the detected objects.\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error opening webcam...\")\n",
    "            return\n",
    "\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(self.output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            self.detect_objects(frame)\n",
    "\n",
    "            cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "            out.write(frame)  # Write the frame to the video writer\n",
    "\n",
    "            # Wait for key press and check if 'q' is pressed\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        # Release video capture, video writer, and destroy windows\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd053c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths and configuration\n",
    "video_path = \"street.mp4\"\n",
    "config_path = \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "model_path = \"frozen_inference_graph.pb\"\n",
    "classes_path = \"coco.names\"\n",
    "output_path = \"output.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d35bc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ObjectDetector class\n",
    "object_detector = ObjectDetector(video_path, config_path, model_path, classes_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa2e9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the video file\n",
    "object_detector.process_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16477dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the webcam feed\n",
    "object_detector.process_webcam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32611137",
   "metadata": {},
   "source": [
    "## Object Detection with GUI\n",
    "\n",
    "This project is an object detection system that can detect objects in a video stream or webcam feed and record the video with highlighted objects. It uses the OpenCV library and a pre-trained deep learning model to perform object detection.\n",
    "\n",
    "### User Guide:\n",
    "\n",
    "1. **Select Video Path**: Click the \"Select Video Path\" button to choose a video file (in MP4 format) that you want to process for object detection.\n",
    "\n",
    "2. **Process Video**: Once you have selected the video file, the \"Process Video\" button will become active. Click it to start the object detection process. The processed video will be displayed in a new window with bounding boxes around detected objects. The FPS (frames per second) of the video will be shown in the top left corner.\n",
    "\n",
    "3. **Select Output Path**: If you want to save the processed video, click the \"Select Output Path\" button to choose the output file location. The processed video will be saved in MP4 format.\n",
    "\n",
    "4. **Process Webcam**: The \"Process Webcam\" button will become active after selecting an output path. Click it to use the webcam feed for object detection. The webcam feed will be displayed in a new window with bounding boxes around detected objects. You can press the 'q' key or close the window to stop the webcam feed.\n",
    "\n",
    "Please note that the object detection model used in this project is based on the COCO dataset, which includes a wide variety of objects. The detected objects will be labeled with their class names and confidence scores.\n",
    "\n",
    "Additionally, please note that the \"Process Video\" and \"Process Webcam\" buttons will only be active after selecting appropriate paths for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04f5cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8ffff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77ea9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector:\n",
    "    \"\"\"\n",
    "    Class for detecting objects in a video stream and recording the video with highlighted objects.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, video_path, config_path, model_path, classes_path, output_path):\n",
    "        \"\"\"\n",
    "        Initialize the ObjectDetector object.\n",
    "\n",
    "        Parameters:\n",
    "            - video_path (str or int): Path to the video file or webcam index.\n",
    "            - config_path (str): Path to the model's configuration file.\n",
    "            - model_path (str): Path to the model's weight file.\n",
    "            - classes_path (str): Path to the file containing class labels.\n",
    "            - output_path (str): Path to save the output video file.\n",
    "        \"\"\"\n",
    "        self.video_path = video_path\n",
    "        self.config_path = config_path\n",
    "        self.model_path = model_path\n",
    "        self.classes_path = classes_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "        self.net = cv2.dnn_DetectionModel(self.model_path, self.config_path)\n",
    "        self.net.setInputSize(320, 320)\n",
    "        self.net.setInputScale(1.0 / 127.5)\n",
    "        self.net.setInputMean((127.5, 127.5, 127.5))\n",
    "        self.net.setInputSwapRB(True)\n",
    "\n",
    "        self.read_classes()\n",
    "\n",
    "    def read_classes(self):\n",
    "        \"\"\"\n",
    "        Read the class labels from the file.\n",
    "        \"\"\"\n",
    "        with open(self.classes_path, 'r') as f:\n",
    "            self.classes_list = f.read().splitlines()\n",
    "\n",
    "        self.classes_list.insert(0, '__Background__')\n",
    "\n",
    "        self.color_list = np.random.uniform(low=0, high=255, size=(len(self.classes_list), 3))\n",
    "\n",
    "    def detect_objects(self, image):\n",
    "        \"\"\"\n",
    "        Detect objects in the given image and draw bounding boxes around them.\n",
    "\n",
    "        Parameters:\n",
    "            - image (numpy.ndarray): Input image array.\n",
    "        \"\"\"\n",
    "        class_label_ids, confidences, bboxes = self.net.detect(image, confThreshold=0.4)\n",
    "\n",
    "        bboxes = list(bboxes)\n",
    "        confidences = list(np.array(confidences).reshape(1, -1)[0])\n",
    "        confidences = list(map(float, confidences))\n",
    "\n",
    "        bbox_indices = cv2.dnn.NMSBoxes(bboxes, confidences, score_threshold=0.5, nms_threshold=0.2)\n",
    "\n",
    "        if len(bbox_indices) != 0:\n",
    "            for i in range(len(bbox_indices)):\n",
    "                bbox = bboxes[np.squeeze(bbox_indices[i])]\n",
    "                class_confidence = confidences[np.squeeze(bbox_indices[i])]\n",
    "                class_label_id = np.squeeze(class_label_ids[np.squeeze(bbox_indices[i])])\n",
    "                class_label = self.classes_list[class_label_id].upper()\n",
    "                class_color = [int(c) for c in self.color_list[class_label_id]]\n",
    "\n",
    "                display_text = \"{}: {:.2f}\".format(class_label, class_confidence)\n",
    "                x, y, w, h = bbox  # Corrected indentation here\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), color=class_color, thickness=1)\n",
    "                cv2.putText(image, display_text, (x, y - 10), cv2.FONT_HERSHEY_PLAIN, 1, class_color, 2)\n",
    "\n",
    "    def process_video(self):\n",
    "        \"\"\"\n",
    "        Process the video file.\n",
    "        \"\"\"\n",
    "\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(self.output_path, fourcc, fps, (width, height))\n",
    "\n",
    "        start_time = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            self.detect_objects(frame)\n",
    "            current_time = time.time()\n",
    "            fps = 1 / (current_time - start_time)\n",
    "            start_time = current_time\n",
    "            cv2.putText(frame, \"FPS: \" + str(int(fps)), (20, 70), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "\n",
    "            if self.output_path:\n",
    "                out.write(frame)\n",
    "\n",
    "            cv2.imshow('Object Detection', frame)\n",
    "            key = cv2.waitKey(1)\n",
    "\n",
    "            # Check if the 'q' key or the window close button (X) is pressed\n",
    "            if key == ord('q') or cv2.getWindowProperty('Object Detection', cv2.WND_PROP_VISIBLE) < 1:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffedc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_video():\n",
    "    \"\"\"\n",
    "    Callback function for selecting the video file.\n",
    "    \"\"\"\n",
    "    video_path = filedialog.askopenfilename(filetypes=[(\"Video Files\", \"*.mp4\")])\n",
    "    if video_path:\n",
    "        video_entry.delete(0, tk.END)\n",
    "        video_entry.insert(tk.END, video_path)\n",
    "        enable_process_video_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85f52467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_output():\n",
    "    \"\"\"\n",
    "    Callback function for selecting the output file.\n",
    "    \"\"\"\n",
    "    output_path = filedialog.asksaveasfilename(defaultextension=\".mp4\", filetypes=[(\"Video Files\", \"*.mp4\")])\n",
    "    output_entry.delete(0, tk.END)\n",
    "    output_entry.insert(tk.END, output_path)\n",
    "    enable_process_webcam_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d19d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_process_video_button():\n",
    "    \"\"\"\n",
    "    Helper function to enable the Process Video button.\n",
    "    \"\"\"\n",
    "    process_video_button.config(state='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a768095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_process_webcam_button():\n",
    "    \"\"\"\n",
    "    Helper function to enable the Process Webcam button.\n",
    "    \"\"\"\n",
    "    process_webcam_button.config(state='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d394f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video():\n",
    "    \"\"\"\n",
    "    Callback function for processing the video file.\n",
    "    \"\"\"\n",
    "    video_path = video_entry.get()\n",
    "    config_path = \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "    model_path = \"frozen_inference_graph.pb\"\n",
    "    classes_path = \"coco.names\"\n",
    "    output_path = None\n",
    "\n",
    "    object_detector = ObjectDetector(video_path, config_path, model_path, classes_path, output_path)\n",
    "    object_detector.process_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "066547e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_webcam():\n",
    "    \"\"\"\n",
    "    Callback function for processing the webcam feed.\n",
    "    \"\"\"\n",
    "    config_path = \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "    model_path = \"frozen_inference_graph.pb\"\n",
    "    classes_path = \"coco.names\"\n",
    "    output_path = output_entry.get()\n",
    "\n",
    "    video_path = 0  # Set video_path to 0 for webcam feed\n",
    "\n",
    "    object_detector = ObjectDetector(video_path, config_path, model_path, classes_path, output_path)\n",
    "    object_detector.process_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22350804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Object Detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0856b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and position the select video path button and entry\n",
    "select_video_button = tk.Button(window, text=\"Select Video Path\", command=select_video)\n",
    "select_video_button.pack()\n",
    "\n",
    "video_entry = tk.Entry(window, width=50)\n",
    "video_entry.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e084aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and position the process video button\n",
    "process_video_button = tk.Button(window, text=\"Process Video\", command=process_video, state='disabled')\n",
    "process_video_button.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1385cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and position the select output recording path button and entry\n",
    "select_output_button = tk.Button(window, text=\"Select Output Path\", command=select_output)\n",
    "select_output_button.pack()\n",
    "output_entry = tk.Entry(window, width=50)\n",
    "output_entry.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03925d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and position the process webcam button\n",
    "process_webcam_button = tk.Button(window, text=\"Process Webcam\", command=process_webcam, state='disabled')\n",
    "process_webcam_button.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c9dd9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bind the window closing event to the exit_application function\n",
    "window.protocol(\"WM_DELETE_WINDOW\", window.destroy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af77a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the main event loop\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435defbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
